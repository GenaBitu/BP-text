\chapter{Multi-instanční učení}
Multi-instanční učení (anglicky \textenglish{\textit{multi-instance learning, MIL}}), poprvé takto popsané v \cite{dietterich_solving_1997}, je variací učení s učitelem (anglicky \textenglish{\textit{supervised learning}}), metody pro určení funkce z trénovacích dat. Předpokládáme vstupní objekty ze vstupního prostoru \( \BPspace X \), výstupní objekty z výstupního prostoru \( \BPspace Y \), kde každému \( x \in \BPspace X \) lze jednoznačně přiřadit \( y \in \BPspace Y \). Tyto výstupní objekty avšak neznáme ani pro trénovací data. Proto seskupujeme vstupní objekty do takzvaných tašek (anglicky \textenglish{\textit{bag}}), označujeme \( b \in \BPspace B \subset \mathcal P ( \BPspace X ) \), kde \( \BPspace B \) je množina všech tašek. Díky tomu můžeme každé tašce jednoznačně přiřadit jeden výstupní objekt dle vztahu
\begin{equation}\label{baglabel}
	y_b = \max_{x \in b} \left( y_x \right) \in \BPspace Y
\end{equation}
a předpokládáme znalost takovýchto výstupních objektů na úrovni tašek. 

Popíšeme zde tři převládající přístupy k řešení Multi-instančních problémů, více viz \cite{pevny_using_2016}.

\section{Paradigma prostoru instancí}
Předpokládáme existenci výstupních objektů pro všechny vstupní objekty (odpovídají instancím), přestože tyto hodnoty neznáme. Pro každou tašku pak předpokládáme výstupní objekt \( y_b \) a snažíme se najít klasifikační funkci \( f : \BPspace X \to \BPspace Y \) a posléze určit
\begin{equation}
	y_b = \max_{x \in b} \left( f \left( x \right) \right)
\end{equation}

\section{Paradigma prostoru tašek}
Předpokládáme pouze existenci výstupních objektů na úrovni tašek. Definujeme kernel funkci
\begin{equation}
	k : \BPspace B \times \BPspace B \to \mathbb R_0^+
\end{equation}
kterou použijeme jako metriku při klasifikaci například algoritmem k--nejbližsích sousedů.

\section{Paradigma vloženého prostoru}
Předpokládáme pouze existenci výstupních objektů na úrovni tašek. Definujeme vkládající funkci \( \phi : \BPspace B \to \BPspace X \) a reprezentujeme kažkou tašku vstupním objektem \( \phi \left( b \right) \in \BPspace X \) a nasledně můzeme použít jakýkoliv algoritmus používaný při klasickém učení s učitelem. Pokud \( \BPspace X = \mathbb R^n \), pak většinou klademe na \( \phi \) podmínku
\begin{equation}
	\left( \exists \psi : \mathbb R^k \to \mathbb R \right) \left( \phi \left( x^{(1)}, \dots, x^{(n)} \right) = \left( \psi \left( x_1^{(1)}, \dots, x_1^{(n)} \right), \dots, \psi \left( x_k^{(1)}, \dots, x_k^{(n)} \right) \right) \right)
\end{equation}

\section{Použitý formalismus}
Dále budeme použivat \( \BPspace X = \mathbb R^n \), \( \BPspace Y = \left\{ -1, +1 \right\} \) a \( \BPspace B = \bigcup_{k = 1}^{\infty} \left( \mathbb R^n \right) ^k \). Prvky \( \BPspace X \) budeme nazývat \textit{vektory příznaků}, prvky \( \BPspace Y \) budeme nazývat \textit{značky}. Instanci budeme považovat za \textit{pozitivní}, pokud je pozitivní její značka, a negativní jinak. Při použití definice \eqref{baglabel} budeme považovat tašku za pozitivní, pokud obsahuje alespoň jednu pozitivní instanci, a negativní, pokud obsahuje pouze negativní instance. Používáme paradigma vloženého prostoru a držíme se dále popsaného formalismu nastíněného v \cite{pevny_using_2016} a \cite{pevny_discriminative_2016}.

Předpokládáme existenci prostoru rozdělení pravděpodobnosti \( \BPspace P^{\BPspace X} \). Každé taška \( b \) je pak realizací nějaké pravděpodobnostní funkce \( P \left( p_b, y_b \right) \) kde \( p_b \in \BPspace P^{\BPspace X} \) je rozdělení pravděpodobnosti instancí v \( b \) a \( y_b \in \BPspace Y \) je značka této tašky. Tedy předpokládáme, že pravděpodobnostní funkce závisí i na značce, tj. \( p_+ \neq p_- \) kde \( p_+ \sim P(p, +1) \) a \( p_- \sim P(p, -1) \). Můžeme potom zapsat prostor všech tašek jako
\begin{equation}
	\BPspace B = \left\{ \left\{ x_1, x_2, \dots, x_n \right\} \in \BPspace P \left( \BPspace X \right) \middle| \left( \forall i \in \hat n \right) \left( x_i \sim p \in \BPspace P^{\BPspace X} \right) \right\}
\end{equation}

Zvolíme \( k : \BPspace X \to \BPspace X \) a \( g : \bigcup_{k = 1}^{\infty} \BPspace X^k \to \BPspace X \) a vkládající funkci definujeme jako
\begin{equation}
	\phi : \BPspace B \to \BPspace X : b \mapsto g \left( \left\{ k \left( x \right) \middle| x \in b \right\} \right)
\end{equation}
Za \( g \) volíme například funkce minimum, maximum, aritmetický průměr. Funkci \( k \) potom hledámealgoritmem pro učení s učitelem. \todo{figure from \cite{pevny_using_2016}}Tedy trénujeme zároveň neuronovou síť určující funkci \( f \) a funkci \( k \).
